import pandas as pd

df = pd.read_csv('offenseval.tsv', sep='\t')

print(df.columns)

label_column = 'subtask_a'  # or whatever it is in your file

print("\nLabel counts:")
print(df[label_column].value_counts())
print("\nLabel percentages:")
print((df[label_column].value_counts(normalize=True) * 100).round(2))

import pandas as pd

# Load the dataset
df = pd.read_csv("offenseval.tsv", sep="\t")

# Preview
print(df.head())
print(df.shape)
print(df.columns)

# Keep only tweet and subtask_a
df = df[['tweet', 'subtask_a']]

# Drop missing values if any
df.dropna(inplace=True)

df.head()

df['label'] = df['subtask_a'].map({'OFF': 1, 'NOT': 0})

df.head()
df['label'].value_counts()

from sklearn.model_selection import train_test_split

X_train, X_test, y_train, y_test = train_test_split(
    df['tweet'],
    df['label'],
    test_size=0.2,
    random_state=42,
    stratify=df['label']
)

import re

def clean_text(text):
    text = text.lower()
    text = re.sub(r'https?://\S+', '', text)     # remove links
    text = re.sub(r'@\w+', '', text)             # remove mentions
    text = re.sub(r'[^a-zA-Z\s]', ' ', text)     # remove special chars
    text = re.sub(r'\s+', ' ', text).strip()     # remove extra spaces
    return text

X_train_clean = X_train.apply(clean_text)
X_test_clean  = X_test.apply(clean_text)

from sklearn.feature_extraction.text import TfidfVectorizer

vectorizer = TfidfVectorizer(
    ngram_range=(1,2),     # word uni + bi-grams
    analyzer='word',
    min_df=5,
    max_df=0.95,
    sublinear_tf=True
)

X_train_vec = vectorizer.fit_transform(X_train_clean)
X_test_vec = vectorizer.transform(X_test_clean)

X_train_vec.shape, X_test_vec.shape

from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report

lr = LogisticRegression(max_iter=300)
lr.fit(X_train_vec, y_train)
lr_pred = lr.predict(X_test_vec)

print("Logistic Regression Results:")
print(classification_report(y_test, lr_pred))

from sklearn.svm import LinearSVC

svm_linear = LinearSVC(C=1.0)
svm_linear.fit(X_train_vec, y_train)
linear_pred = svm_linear.predict(X_test_vec)

print("Linear SVM Results:")
print(classification_report(y_test, linear_pred))

from sklearn.svm import SVC

svm_rbf = SVC(kernel='rbf', gamma='scale', C=1.0)
svm_rbf.fit(X_train_vec, y_train)
rbf_pred = svm_rbf.predict(X_test_vec)

print("RBF SVM Results:")
print(classification_report(y_test, rbf_pred))

from sklearn.model_selection import GridSearchCV

param_grid = {
    'C': [0.1, 1, 10],
    'gamma': [1, 0.1, 0.01, 0.001]
}

svm_rbf = SVC(kernel='rbf')

grid = GridSearchCV(
    svm_rbf,
    param_grid,
    cv=3,
    scoring='f1',
    verbose=2
)

grid.fit(X_train_vec, y_train)

print("Best parameters:", grid.best_params_)
print("Best CV score:", grid.best_score_)

best_svm = grid.best_estimator_
best_pred = best_svm.predict(X_test_vec)

print("Best Tuned RBF SVM Results:")
print(classification_report(y_test, best_pred))

from sklearn.metrics import confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

cm = confusion_matrix(y_test, best_pred)

plt.figure(figsize=(5,4))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',
            xticklabels=['NOT','OFF'],
            yticklabels=['NOT','OFF'])
plt.xlabel('Predicted Label')
plt.ylabel('True Label')
plt.title('Confusion Matrix — Tuned RBF SVM')
plt.show()

from sklearn.model_selection import learning_curve
import numpy as np

train_sizes, train_scores, test_scores = learning_curve(
    best_svm,
    X_train_vec,
    y_train,
    cv=3,
    scoring='f1',
    train_sizes=np.linspace(0.1, 1.0, 5),
    n_jobs=-1
)

train_mean = np.mean(train_scores, axis=1)
test_mean = np.mean(test_scores, axis=1)

plt.figure(figsize=(8,5))
plt.plot(train_sizes, train_mean, marker='o', label='Training F1')
plt.plot(train_sizes, test_mean, marker='o', label='Validation F1')
plt.title("Learning Curve — Tuned RBF SVM")
plt.xlabel("Training Size")
plt.ylabel("F1 Score")
plt.legend()
plt.grid(True)
plt.show()
